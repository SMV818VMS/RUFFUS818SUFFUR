{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning ruffus\n",
    "\n",
    "Computational pipelines transform your data in stages until the final result is produced. One easy way to understand pipelines is by imagining your data flowing across a series of pipes until it reaches its final destination. Even quite complicated processes can be broken into simple stages. Of course, it helps to visualise the whole process.\n",
    "\n",
    "Ruffus is a way of automating the plumbing in your pipeline: You supply the python functions which perform the data transformation, and tell Ruffus how these pipeline task functions are connected up. Ruffus will make sure that the right data flows down your pipeline in the right way at the right time.\n",
    "\n",
    "### First example: a FASTA to statistics pipeline\n",
    "\n",
    "Start loading the package and defining the functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ruffus import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate some datasets:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "starting_files = [\"a.fasta\", \"b.fasta\", \"c.fasta\"]\n",
    "\n",
    "for ff in starting_files:\n",
    "    open(ff, \"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ruffus makes exactly the same function calls on your behalf. However, first, we need to tell Ruffus what the arguments should be for each of the function calls.\n",
    "\n",
    "- The Input is easy: This is either the starting file set (*.fasta) or whatever is produced by the previous stage.\n",
    "- The Output file name is the same as the Input but with the appropriate extension.\n",
    "\n",
    "These are specified using the Ruffus @transform decorator as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "error_duplicate_task_name",
     "evalue": "    \n    \n    \n    Same task name map_dna_sequence specified multiple times in the same pipeline (main)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror_duplicate_task_name\u001b[0m                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-939a553fe5b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m @transform(starting_files,                     # Input = starting files\n\u001b[0;32m      5\u001b[0m             \u001b[0msuffix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".fasta\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m                  \u001b[1;31m#         suffix = .fasta\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \".sam\")                            # Output  suffix = .sam\n\u001b[0m\u001b[0;32m      7\u001b[0m def map_dna_sequence(input_file,\n\u001b[0;32m      8\u001b[0m                     output_file):\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/ruffus/task.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, task_func)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[1;31m# add task to main pipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;31m# check for duplicate tasks inside _create_task\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m         \u001b[0mtask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_task\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;31m# call the method called\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/ruffus/task.pyc\u001b[0m in \u001b[0;36m_create_task\u001b[1;34m(self, task_func, task_name)\u001b[0m\n\u001b[0;32m    960\u001b[0m         \u001b[1;31m# task name then OK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 962\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mTask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/ruffus/task.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, task_name, pipeline, command_str)\u001b[0m\n\u001b[0;32m   1959\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtask_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1960\u001b[0m             raise error_duplicate_task_name(\"Same task name %s specified multiple times in the \"\n\u001b[1;32m-> 1961\u001b[1;33m                                             \"same pipeline (%s)\" % (task_name, self.pipeline.name))\n\u001b[0m\u001b[0;32m   1962\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror_duplicate_task_name\u001b[0m:     \n    \n    \n    Same task name map_dna_sequence specified multiple times in the same pipeline (main)"
     ]
    }
   ],
   "source": [
    "#\n",
    "#   STAGE 1 fasta->sam\n",
    "#\n",
    "@transform(starting_files,                     # Input = starting files\n",
    "            suffix(\".fasta\"),                  #         suffix = .fasta\n",
    "            \".sam\")                            # Output  suffix = .sam\n",
    "def map_dna_sequence(input_file,\n",
    "                    output_file):\n",
    "    ii = open(input_file)\n",
    "    oo = open(output_file, \"w\")\n",
    "\n",
    "#\n",
    "#   STAGE 2 sam->bam\n",
    "#\n",
    "@transform(map_dna_sequence,                   # Input = previous stage\n",
    "            suffix(\".sam\"),                    #         suffix = .sam\n",
    "            \".bam\")                            # Output  suffix = .bam\n",
    "def compress_sam_file(input_file,\n",
    "                      output_file):\n",
    "    ii = open(input_file)\n",
    "    oo = open(output_file, \"w\")\n",
    "\n",
    "#\n",
    "#   STAGE 3 bam->statistics\n",
    "#\n",
    "@transform(compress_sam_file,                  # Input = previous stage\n",
    "            suffix(\".bam\"),                    #         suffix = .bam\n",
    "            \".statistics\",                     # Output  suffix = .statistics\n",
    "            \"use_linear_model\")                # Extra statistics parameter\n",
    "def summarise_bam_file(input_file,\n",
    "                       output_file,\n",
    "                       extra_stats_parameter):\n",
    "    \"\"\"\n",
    "    Sketch of real analysis function\n",
    "    \"\"\"\n",
    "    ii = open(input_file)\n",
    "    oo = open(output_file, \"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the pipeline with the Ruffus function pipeline_run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "________________________________________\n",
      "Tasks which will be run:\n",
      "\n",
      "\n",
      "Task enters queue = 'map_dna_sequence' \n",
      "Completed Task = 'map_dna_sequence' \n",
      "Task enters queue = 'compress_sam_file' \n",
      "Completed Task = 'compress_sam_file' \n",
      "Task enters queue = 'summarise_bam_file' \n",
      "Completed Task = 'summarise_bam_file' \n"
     ]
    }
   ],
   "source": [
    "pipeline_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
